# TaskNestAPI

## ğŸŒŸ Description

Pywebscraper is a Python-based web scraping project designed to extract and store structured data from websites into a PostgreSQL database. It is built with scalability, maintainability, and testing in mind, making it suitable for both small experiments and production-level scraping tasks.

---

## ğŸ¯ Purpose

The main goals of this project are:
- To demonstrate how to build a clean and modular Python web scraping pipeline.
- To show how to integrate Python scraping code with a PostgreSQL database.
- To provide a ready-to-use project structure that supports testing and containerization.

---

## ğŸ› ï¸ Technologies Used

- **Python 3.11+**
- **PostgreSQL** (local or Docker)
- **SQLAlchemy** (ORM)
- **Requests** (HTTP client)
- **BeautifulSoup4** (HTML parsing)
- **pytest** (testing framework)
- **Docker** & **Docker Compose** (optional containerization)

---

## ğŸ› ï¸ Installation Guidance

1. **Clone the repository**

   ```bash
   git clone https://github.com/abramdarmaputra/Pywebscraper.git
   cd Pywebscraper
````

2. **Create and activate a virtual environment**

   ```bash
   python -m venv .venv
   source .venv/bin/activate     # Linux / Mac
   .venv\Scripts\activate        # Windows
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Set up PostgreSQL**

   * Local:

     ```sql
     CREATE ROLE scraper_user WITH LOGIN PASSWORD 'scrape_password';
     CREATE DATABASE scraper_db OWNER scraper_user;
     GRANT ALL PRIVILEGES ON DATABASE scraper_db TO scraper_user;
     ```
   * Docker:

     ```bash
     docker run -d --name pg \
       -e POSTGRES_USER=scraper_user \
       -e POSTGRES_PASSWORD=scrape_password \
       -e POSTGRES_DB=scraper_db \
       -p 5432:5432 postgres:16
     ```

5. **Configure environment variables**
   Create a `.env` file:

   ```
   DATABASE_URL=postgresql://scraper_user:scrape_password_@localhost:5432/scraper_db
   BASE_URL=https://quotes.toscrape.com
   PAGES=3
   ```

6. **Run the scraper**

   ```bash
   python -m src.main --create-tables --pages 3
   ```

---

## ğŸ“‚ Directory Structure

```
Pywebscraper/
â”‚
â”œâ”€â”€ src/                         # Main application code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ db.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ parser.py
â”‚   â”œâ”€â”€ scraper.py
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ tests/                       # Unit & integration tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_parser.py
â”‚   â”œâ”€â”€ test_scraper.py
â”‚   â””â”€â”€ test_db.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ .env
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ğŸ§ª Testing

Run tests from the project root:

```bash
pytest -q
```
---

## ğŸ“ License

This project is licensed under the MIT License.
